#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
çµ±åˆç‰ˆMLBãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã¨HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’åŒæ™‚ç”Ÿæˆ
"""

import os
import sys
import json
from datetime import datetime, timedelta
from pathlib import Path

# æ—¢å­˜ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from scripts.mlb_complete_report_real import generate_complete_mlb_report
from scripts.report_visualizer import MLBReportVisualizer

def save_report_as_json(report_text, output_path):
    """
    ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’JSONå½¢å¼ã§ä¿å­˜
    """
    # ãƒ¬ãƒãƒ¼ãƒˆã‚’è§£æã—ã¦JSONåŒ–ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    report_data = {
        "date": datetime.now().strftime("%Y-%m-%d"),
        "raw_text": report_text,
        "games": [],
        "team_stats": {},
        "player_stats": {
            "batters": [],
            "pitchers": []
        }
    }
    
    # ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡ºï¼ˆå®Ÿè£…ä¾‹ï¼‰
    lines = report_text.split('\n')
    current_section = None
    
    for line in lines:
        line = line.strip()
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¤å®š
        if 'è©¦åˆçµæœ' in line or 'Game Results' in line:
            current_section = 'games'
        elif 'æ‰“æ’ƒæˆç¸¾' in line or 'Batting Stats' in line:
            current_section = 'batting'
        elif 'æŠ•æ‰‹æˆç¸¾' in line or 'Pitching Stats' in line:
            current_section = 'pitching'
        
        # ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆ - å®Ÿéš›ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«åˆã‚ã›ã¦èª¿æ•´ï¼‰
        if current_section == 'games' and ' vs ' in line:
            # è©¦åˆæƒ…å ±ã®æŠ½å‡º
            parts = line.split(' vs ')
            if len(parts) == 2:
                away_info = parts[0].strip()
                home_info = parts[1].strip()
                
                # ã‚¹ã‚³ã‚¢æŠ½å‡ºï¼ˆä¾‹: "Yankees 5" -> team="Yankees", score=5ï¼‰
                game_info = {
                    "away_team": away_info.split()[0] if away_info else "",
                    "home_team": home_info.split()[0] if home_info else "",
                    "away_score": 0,
                    "home_score": 0,
                    "status": "Final"
                }
                report_data["games"].append(game_info)
    
    # JSONä¿å­˜
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
    
    return report_data

def integrate_mlb_reports():
    """
    çµ±åˆç‰ˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    1. ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    2. JSONãƒ‡ãƒ¼ã‚¿ä¿å­˜
    3. HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    """
    print("=" * 60)
    print("âš¾ MLBçµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 60)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs("daily_reports", exist_ok=True)
    os.makedirs("daily_reports/html", exist_ok=True)
    os.makedirs("daily_reports/json", exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    date_str = datetime.now().strftime("%Y%m%d")
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    print("\nğŸ“ ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
    text_report = generate_complete_mlb_report()
    
    # ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    text_path = f"daily_reports/mlb_report_{timestamp}.txt"
    with open(text_path, 'w', encoding='utf-8') as f:
        f.write(text_report)
    print(f"âœ… ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {text_path}")
    
    # ã‚¹ãƒ†ãƒƒãƒ—2: JSONãƒ‡ãƒ¼ã‚¿ä¿å­˜
    print("\nğŸ“Š JSONãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")
    json_path = f"daily_reports/json/mlb_data_{date_str}.json"
    report_data = save_report_as_json(text_report, json_path)
    print(f"âœ… JSONãƒ‡ãƒ¼ã‚¿ä¿å­˜: {json_path}")
    
    # ã‚¹ãƒ†ãƒƒãƒ—3: HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    print("\nğŸ¨ HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
    visualizer = MLBReportVisualizer()
    visualizer.report_data = report_data
    html_path = f"daily_reports/html/mlb_report_{date_str}.html"
    visualizer.create_html_report(html_path)
    print(f"âœ… HTMLãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {html_path}")
    
    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³: PDFç”Ÿæˆ
    try:
        print("\nğŸ“„ PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
        pdf_path = visualizer.create_pdf_report(html_path)
        if pdf_path:
            print(f"âœ… PDFãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {pdf_path}")
    except Exception as e:
        print(f"âš ï¸ PDFç”Ÿæˆã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ: {e}")
    
    # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    print("\n" + "=" * 60)
    print("âœ¨ å…¨ãƒ¬ãƒãƒ¼ãƒˆã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print("=" * 60)
    print(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆ: {text_path}")
    print(f"ğŸ“ JSON: {json_path}")
    print(f"ğŸ“ HTML: {html_path}")
    print("=" * 60)
    
    return {
        "text": text_path,
        "json": json_path,
        "html": html_path
    }

def cleanup_old_reports(days_to_keep=7):
    """
    å¤ã„ãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    """
    cutoff_date = datetime.now() - timedelta(days=days_to_keep)
    
    for folder in ["daily_reports", "daily_reports/html", "daily_reports/json"]:
        if os.path.exists(folder):
            for file in os.listdir(folder):
                file_path = os.path.join(folder, file)
                if os.path.isfile(file_path):
                    file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                    if file_time < cutoff_date:
                        os.remove(file_path)
                        print(f"ğŸ—‘ï¸ å‰Šé™¤: {file_path}")

if __name__ == "__main__":
    try:
        # å¤ã„ãƒ¬ãƒãƒ¼ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        # cleanup_old_reports(days_to_keep=30)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        integrate_mlb_reports()
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)